1a Dificuldade  - trabalhar com o github --> dar fork no repositório

2a              - Baixar os requisitos, provavelmente dando problema devido a partição da minha maquina

pip._vendor.urllib3.exceptions.ProtocolError: ("Connection broken: OSError(28, 'No space left on device')", OSError(28, 'No space left on device'))

Tive problemas para organização do espaço para o trabalho, solução --> criei um ambinte virtual conda na pasta do projeto, nao tem espaço no anaconda do linux em si

3a              - Dificuldade com a utilização do linux, devido a falta de intimidade com o OS




Tendo o projeto funcionando em maos, agora penso em como resolver esses problemas:
Dificuldade 1 --> Parece, de fato, o mais facil. O agente somente deve se movimentar afim de desviar de cada obstaculo
Dificuldade 2 --> Os obstaculos se movem, oque pode dificultar o algoritmo para como o 
Dificuldade 3 --> Aqui tem-se multiplos agentes, mas eles estao todos indo para o mesmo objetivo, a optimização desse movimento pode vim a partir da separaçao de
qual agente vai para qual objetivo

Dificuldade 4 --> Aqui tem-se multiplos agentes, como na Dificuldade 3, entretanto, aqui se tem menos objetivos. provavelmente deve-se deixar os agentes mais distantes
dos objetivo em posiçoes estratetigicas, para que esses fiquem mais proximos dos objetivos



           ## Dificuldade 1 

Lendo os arquivo, fico em duvida em como eu começo, minha ideia inicial é passar a distancia relativa do player e todos os obstaculos e se ele ficarem à uma distancia
a se colidirem, altero o trajeto aplicando algum algoritimo de procura (talvez depth first search)

-- Estou tendo dificuldade em puxar a posiçoes de cada obstaculo

Erro extremamente besta, que me levou a perder bastate tempo, a variavel self.opponents estava puxando as posiçoes de todos, para pegar a posiçâo basta fazer:
self.opponents[id].x ou self.opponents[id].y ---- Uso 'id' pois é um dicionario oordenado

Agora que ja matei esse leao, agora irei pensar mais no algoritimo a ser usado. Atualmente estou fazendo ele ir diretamente para o alvo em uma reta e se ele encontrar
um obstaculo, move de forma aleatoria

Referência: https://fei.edu.br/robofei/ics/IC-Leonardo-2020.pdf
            https://www.datacamp.com/tutorial/a-star-algorithm


8/01

Atualmente o codigo esta rodando o algoritimo de A* sem parar, nao sei oque esta errado. Fiz Vários testes para checar aonde esta dando erro. Minha primeira ideia era desenhar 
no mapa os calculos que do caminho que estao sendo feitos, analogamente à linha de caminho deixada pelo robo apos andar.

Pessoal da equipe me falou que a no agente.py as distancias estao em metros e o centro é o centro do campo de futebol

Acredito que o algoritimo esta funcionando, mas ele esta rodando multiplas vezes. Estou morto verei esse erro amanha, provavelmente terei que passar todo o codigo para O
arquivo Navigation.py

Resultado de hoje:

posição inicial: (-1.1050963446736606, -0.2037360151424596)
Caminho encontrado: [(-1.1050963446736606, -0.2037360151424596), (-1.2050963446736607, -0.2037360151424596),
(-1.2050963446736607, -0.10373601514245959), (-1.2050963446736607, -0.003736015142459581), (-1.1050963446736606, -0.003736015142459581),
(-1.1050963446736606, 0.09626398485754042), (-1.0050963446736605, 0.09626398485754042), (-0.9050963446736605, 0.09626398485754042), 
(-0.8050963446736605, 0.09626398485754042), (-0.7050963446736606, 0.09626398485754042), (-0.6050963446736606, 0.09626398485754042), 
(-0.5050963446736606, 0.09626398485754042), (-0.4050963446736606, 0.09626398485754042), (-0.30509634467366065, 0.09626398485754042), 
(-0.20509634467366064, 0.09626398485754042), (-0.10509634467366064, 0.09626398485754042), (-0.00509634467366063, 0.09626398485754042), 
(0.09490365532633938, 0.09626398485754042), (0.19490365532633938, 0.09626398485754042), (0.2949036553263394, 0.09626398485754042), 
(0.3949036553263394, 0.09626398485754042), (0.4949036553263394, 0.09626398485754042), (0.5949036553263394, 0.09626398485754042), 
(0.6949036553263394, 0.09626398485754042), (0.7949036553263393, 0.09626398485754042), (0.8949036553263393, 0.09626398485754042), 
(0.9949036553263393, 0.09626398485754042), (1.0949036553263394, 0.09626398485754042), (1.1949036553263395, 0.09626398485754042), 
(1.2949036553263396, 0.09626398485754042), (1.3949036553263396, 0.09626398485754042), (1.4949036553263397, 0.09626398485754042), 
(1.5949036553263398, 0.09626398485754042), (1.69490365532634, 0.09626398485754042), (1.79490365532634, 0.09626398485754042),
(1.89490365532634, 0.09626398485754042), (1.89490365532634, 0.19626398485754043), (1.9949036553263402, 0.19626398485754043)], 
objetivo: (2.1258295745882934, 0.3539119282360874)



09/01

Tive uma ideia ontem antes de dormir, guardar nas caracteristicas do agente os alvos que estao ativos, assim, o calculo para o path será feito somente uma vez
Funcionou!

Agora ele está fazendo o caminho guardado, mas preciso que ele va para cada ponto de cada vez

ITS ALIVEEEEEE
funciona, mas esta muito lento, verei o que fazer: talvez veja aquele negocio de mice maze la

